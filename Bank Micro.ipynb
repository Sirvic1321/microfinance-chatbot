{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install panda scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: panda in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (0.3.1)\r\nRequirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.5.1)\r\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from panda) (2.32.3)\r\nRequirement already satisfied: setuptools in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from panda) (75.8.0)\r\nRequirement already satisfied: scipy>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (1.11.0)\r\nRequirement already satisfied: numpy>=1.19.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\r\nRequirement already satisfied: joblib>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\r\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\r\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->panda) (3.10)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->panda) (1.26.20)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->panda) (3.4.1)\r\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests->panda) (2025.1.31)\r\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "    Uninstalling transformers-4.30.1:\n      Successfully uninstalled transformers-4.30.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nazureml-automl-dnn-nlp 1.60.0 requires torch==2.2.2, but you have torch 2.6.0 which is incompatible.\nazureml-automl-dnn-nlp 1.60.0 requires transformers[sentencepiece,torch]<=4.48.0, but you have transformers 4.53.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed sentence-transformers-5.0.0 tokenizers-0.21.2 transformers-4.53.2\n"
        }
      ],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from chatbot import FAQChatbot\n",
        "\n",
        "# Create chatbot instance\n",
        "bot = FAQChatbot('data/FAQ.csv')\n",
        "\n",
        "# Test matching\n",
        "user_question = \"How can I get a loan?\"\n",
        "q, a, score = bot.get_best_match(user_question)\n",
        "\n",
        "print(f\"User Question: {user_question}\")\n",
        "print(f\"Matched FAQ: {q}\")\n",
        "print(f\"Answer: {a}\")\n",
        "print(f\"Confidence Score: {score:.2f}\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'chatbot'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchatbot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAQChatbot\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create chatbot instance\u001b[39;00m\n\u001b[1;32m      4\u001b[0m bot \u001b[38;5;241m=\u001b[39m FAQChatbot(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/FAQ.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chatbot'"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1752302424692
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/azurecomp/code/Users/support/Bank Micro'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1752302621927
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chatbot import FAQChatbot"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'chatbot'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchatbot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAQChatbot\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chatbot'"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1752303627894
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "os.listdir('.')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "['.amlignore',\n '.amlignore.amltmp',\n '.ipynb_aml_checkpoints',\n 'bank chatbot.py.amltmp',\n 'Bank Micro.ipynb',\n 'bank micro.ipynb.amltmp',\n 'bchatbot.py.amltmp',\n 'chatbot.py',\n 'chatbot.py.amltmp',\n 'faq.amltmp',\n 'FAQ.csv']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1752303819790
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"chatbot.py\",\"r\") as file:\n",
        "    print(file.read())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "# chatbot.py\nimport pandas as pd\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\nclass FAQChatbot:\n    def __init__(self, csv_path):\n        self.faqs = pd.read_csv(csv_path)\n        self.questions = self.faqs['question'].tolist()\n        self.answers = self.faqs['answer'].tolist()\n\n        self.vectorizer = TfidfVectorizer()\n        self.question_vectors = self.vectorizer.fit_transform(self.questions)\n\n    def get_best_match(self, user_input):\n        user_vec = self.vectorizer.transform([user_input])\n        similarities = cosine_similarity(user_vec, self.question_vectors).flatten()\n        best_idx = similarities.argmax()\n        best_score = similarities[best_idx]\n\n        # Return answer and score\n        return self.questions[best_idx], self.answers[best_idx], best_score\n\n    def get_top_n_matches(self, user_input, n=3):\n        user_vec = self.vectorizer.transform([user_input])\n        similarities = cosine_similarity(user_vec, self.question_vectors).flatten()\n        top_indices = similarities.argsort()[-n:][::-1]\n        results = []\n\n        for idx in top_indices:\n            results.append({\n                \"question\": self.questions[idx],\n                \"answer\": self.answers[idx],\n                \"score\": similarities[idx]\n            })\n\n        return results\n\n    def save_unanswered(self, user_input, path='logs/unknown_questions.csv'):\n        try:\n            df = pd.read_csv(path)\n        except FileNotFoundError:\n            df = pd.DataFrame(columns=['question'])\n\n        new_row = pd.DataFrame({'question': [user_input]})\n        df = pd.concat([df, new_row], ignore_index=True)\n        df.to_csv(path, index=False)\n"
        }
      ],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1752304309187
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chatbot import FAQChatbot"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1752304499621
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chatbot import FAQChatbot\n",
        "\n",
        "# Create chatbot instance\n",
        "bot = FAQChatbot(\"faq.csv\")\n",
        "question, answer, score = bot.get_best_match(\"How do I apply for a loan?\")\n",
        "print(f\"Matched Question: {question}\")\n",
        "print(f\"Answer: {answer}\")\n",
        "print(f\"Confidence Score: {score:.2f}\")"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "np.nan is an invalid document, expected byte or unicode string.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchatbot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAQChatbot\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create chatbot instance\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m bot \u001b[38;5;241m=\u001b[39m \u001b[43mFAQChatbot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfaq.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m question, answer, score \u001b[38;5;241m=\u001b[39m bot\u001b[38;5;241m.\u001b[39mget_best_match(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow do I apply for a loan?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatched Question: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/azurecomp/code/Users/support/Bank Micro/chatbot.py:13\u001b[0m, in \u001b[0;36mFAQChatbot.__init__\u001b[0;34m(self, csv_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfaqs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manswers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfaqs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestion_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestions)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2090\u001b[0m )\n\u001b[0;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1369\u001b[0m             )\n\u001b[1;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1259\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1258\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:103\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:236\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    233\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_error)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
            "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1752310005921
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"faq.csv\", encoding='cp1252')\n",
        "print(df.columns)\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Index(['question', 'answer'], dtype='object')\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "                                   question  \\\n0          How do I open a savings account?   \n1     What is the minimum balance required?   \n2                How do I apply for a loan?   \n3         What types of loans do you offer?   \n4  What is the interest rate on your loans?   \n\n                                              answer  \n0  You can open a savings account at any TrustMic...  \n1   You only need ?500 to open and maintain a bas...  \n2   To apply for a loan, visit any branch with yo...  \n3  We offer personal loans, SME loans, group loan...  \n4  Our loan interest rates start at 3% per month ...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>How do I open a savings account?</td>\n      <td>You can open a savings account at any TrustMic...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the minimum balance required?</td>\n      <td>You only need ?500 to open and maintain a bas...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>How do I apply for a loan?</td>\n      <td>To apply for a loan, visit any branch with yo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>What types of loans do you offer?</td>\n      <td>We offer personal loans, SME loans, group loan...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>What is the interest rate on your loans?</td>\n      <td>Our loan interest rates start at 3% per month ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1752310021616
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chatbot import FAQChatbot\n",
        "\n",
        "bot = FAQChatbot(\"faq.csv\")\n",
        "q, a, score = bot.get_best_match(\"How do I apply for a loan?\")\n",
        "print(\"Matched Question:\", q)\n",
        "print(\"Answer:\", a)\n",
        "print(\"Score:\", score)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "np.nan is an invalid document, expected byte or unicode string.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchatbot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FAQChatbot\n\u001b[0;32m----> 3\u001b[0m bot \u001b[38;5;241m=\u001b[39m \u001b[43mFAQChatbot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfaq.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m q, a, score \u001b[38;5;241m=\u001b[39m bot\u001b[38;5;241m.\u001b[39mget_best_match(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow do I apply for a loan?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatched Question:\u001b[39m\u001b[38;5;124m\"\u001b[39m, q)\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/azurecomp/code/Users/support/Bank Micro/chatbot.py:13\u001b[0m, in \u001b[0;36mFAQChatbot.__init__\u001b[0;34m(self, csv_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfaqs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manswers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfaqs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestion_vectors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquestions)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[1;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[1;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[1;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[1;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[1;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[1;32m   2090\u001b[0m )\n\u001b[0;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[1;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[1;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1369\u001b[0m             )\n\u001b[1;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1259\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1258\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1261\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:103\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m decoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m analyzer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    105\u001b[0m     doc \u001b[38;5;241m=\u001b[39m analyzer(doc)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:236\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    233\u001b[0m     doc \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecode_error)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m doc \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan:\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    238\u001b[0m     )\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
            "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1752310681593
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV with proper encoding\n",
        "df = pd.read_csv(\"faq.csv\", encoding=\"cp1252\")\n",
        "\n",
        "# Clean column headers (strip spaces and lowercase)\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "\n",
        "# Drop rows where question or answer is missing\n",
        "df_cleaned = df.dropna(subset=[\"question\", \"answer\"])\n",
        "\n",
        "# Optional: Reset the index\n",
        "df_cleaned = df_cleaned.reset_index(drop=True)\n",
        "\n",
        "# Save cleaned version back to a new CSV (so chatbot uses it)\n",
        "df_cleaned.to_csv(\"faq_clean.csv\", index=False)\n",
        "\n",
        "print(\"âœ… Cleaned and saved as faq_clean.csv\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "âœ… Cleaned and saved as faq_clean.csv\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1752311644308
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from chatbot import FAQChatbot\n",
        "\n",
        "bot = FAQChatbot(\"faq_clean.csv\")\n",
        "q, a, score = bot.get_best_match(\"How do I apply for a loan?\")\n",
        "print(\"Matched Question:\", q)\n",
        "print(\"Answer:\", a)\n",
        "print(\"Score:\", score)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Matched Question: How do I apply for a loan?\nAnswer:  To apply for a loan, visit any branch with your valid ID, a recent utility bill, and proof of income. You can also apply online through our mobile-friendly platform.\nScore: 1.0000000000000002\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1752311094392
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ğŸ‘‹ Welcome to TrustMicro FAQ Chatbot. How can I help you with our services today?\")\n",
        "print(\"Type your question below. Type 'exit' or 'quit' to end the chat.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"You: \").strip()\n",
        "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"Chatbot: Goodbye! Have a nice day. ğŸ‘‹\")\n",
        "        break\n",
        "\n",
        "    # Get the best match\n",
        "    question, answer, score = bot.get_best_match(user_input)\n",
        "\n",
        "    if score < 0.3:\n",
        "        print(\"Chatbot: I'm sorry, I don't have an answer for that. Please ask something else.\")\n",
        "    else:\n",
        "        print(f\"Chatbot: {answer}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "ğŸ‘‹ Welcome to TrustMicro FAQ Chatbot. How can I help you with our services today?\nType your question below. Type 'exit' or 'quit' to end the chat.\n\n"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType your question below. Type \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to end the chat.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatbot: Goodbye! Have a nice day. ğŸ‘‹\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.10/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1752312849799
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting streamlit\n  Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n\u001b[?25hRequirement already satisfied: pandas<3,>=1.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (1.5.3)\nRequirement already satisfied: pillow<12,>=7.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (9.2.0)\nRequirement already satisfied: tenacity<10,>=8.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (9.1.2)\nRequirement already satisfied: typing-extensions<5,>=4.4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (4.13.2)\nRequirement already satisfied: packaging<26,>=20 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (25.0)\nRequirement already satisfied: protobuf<7,>=3.20 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (4.25.6)\nRequirement already satisfied: click<9,>=7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (8.1.8)\nRequirement already satisfied: toml<2,>=0.10.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (0.10.2)\nRequirement already satisfied: cachetools<7,>=4.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (5.5.2)\nRequirement already satisfied: pyarrow>=7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (14.0.2)\nCollecting watchdog<7,>=2.1.5\n  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (3.1.44)\nCollecting pydeck<1,>=0.8.0b4\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<3,>=1.23 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (1.26.4)\nRequirement already satisfied: blinker<2,>=1.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (1.9.0)\nRequirement already satisfied: requests<3,>=2.27 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (2.32.3)\nCollecting altair<6,>=4.0\n  Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from streamlit) (6.4.2)\nRequirement already satisfied: jsonschema>=3.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\nRequirement already satisfied: jinja2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\nRequirement already satisfied: narwhals>=1.14.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit) (1.35.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\nRequirement already satisfied: python-dateutil>=2.8.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from pandas<3,>=1.4.0->streamlit) (2022.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.4.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (2025.1.31)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (1.26.20)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.27->streamlit) (3.10)\nRequirement already satisfied: smmap<6,>=3.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.1)\nRequirement already satisfied: referencing>=0.28.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\nRequirement already satisfied: attrs>=22.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas<3,>=1.4.0->streamlit) (1.17.0)\nInstalling collected packages: watchdog, pydeck, altair, streamlit\nSuccessfully installed altair-5.5.0 pydeck-0.9.1 streamlit-1.46.1 watchdog-6.0.0\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1752312900777
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "streamlit run app.py"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (3737097518.py, line 1)",
          "traceback": [
            "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    streamlit run app.py\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1752314220815
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.10 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}